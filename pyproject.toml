[project]
name = "RAG-PlayGround"
version = "0.1.0"
description = "This is a RAG PlayGround where one can test different RAG techniques."
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "streamlit==1.40.0",
    "sentence-transformers==3.1.1",
    "pypdf2==3.0.1",
    "pillow==11.0.0",
    "opensearch-py==2.6.0",
    "torch==2.2.2",
    "requests==2.27.1",
    "ollama==0.3.3",
    "pycryptodome==3.21.0",
    "langchain==0.3.7",
    "langchain-community==0.3.5",
    "langchain-text-splitters==0.3.2",
    "unstructured[all-docs]",
    "ipython==8.29.0",
    "rapidocr-onnxruntime==1.3.25",
    "tiktoken==0.8.0",
    "watchdog==5.0.3",
    "ruff==0.7.3",
    "black==24.10.0",
    "isort==5.13.2",
    "mypy==1.13.0",
    "python-dotenv>=1.0.1",
    "langchain-huggingface>=0.1.2",
    "langchain-ollama>=0.2.1",
    "langchainhub>=0.1.21",
    "pre-commit>=4.0.1",
    "pandas-stubs>=2.2.3.241126",
]

[tool.mypy]
# Platform configuration
python_version = "3.11"
# imports related
ignore_missing_imports = true
follow_imports = "silent"
# None and Optional handling
no_implicit_optional = true
strict_optional = true
# Configuring warnings
warn_unused_configs = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
warn_return_any = false
# Untyped definitions and calls
check_untyped_defs = true
disallow_untyped_calls = false
disallow_untyped_defs = false
disallow_incomplete_defs = false
disallow_untyped_decorators = false
# Disallow dynamic typing
disallow_subclassing_any = true
disallow_any_unimported = false
disallow_any_expr = false
disallow_any_decorated = false
disallow_any_explicit = false
disallow_any_generics = false
# Miscellaneous strictness flags
allow_untyped_globals = true
allow_redefinition = false
local_partial_types = false
implicit_reexport = true
strict_equality = true
# Configuring error messages
show_error_context = true
show_column_numbers = true
show_error_codes = true
disable_error_code = "operator,var-annotated,unreachable,func-returns-value,union-attr"

[tool.ruff]
lint.select = [
    "I", # isort
    "E", # pycodestyle
    "F", # pyflakes
    "W", # pycodestyle
    "C90", # mccabe complexity
    "N", # pep8 naming
    "D", # pycodestyle
    "ANN", # flake8-annotations
    "B", # flake8-bugbear
    "UP", # pyupgrade
    "PERF", # perflint
    "FBT",  # flake8-boolean-trap
    "COM",  # flake8-commas
    "PIE",  #flake8-pie
    "Q",    # flake8-quotes
    "SIM",  # flake8-simplify
    "TID",  # flake8-tidy
    "ARG",  # flake8-unusued-arguments
    "FIX",  # flake8-fixme
    "ERA",  # eradicate
    "PD",   # pandas-vet
    "PL",   # pylint
    "TRY",  # tryceratops
]

lint.ignore = [
    "E501", # line too long
    "COM812", # trailing comma missing
    "ARG001", # unusued function argument kwargs
    "UP035", # deprecated objects from typing (correct but not in line with legacy code)
    "UP006", # use list, tuple, dict instead of the legacy from typing (correct but not in line with legacy code)
    "TRY003", # long messages outside exception class, suppress this check as it is too strict (custom exception should be needed)
    "ANN003", # type annotation for **kwargs
    "D205", # ugly formatting
    "D404", # any first word in docstring
    "D212",
    "D213",
    "D203",
    "D211",
    "D401",
    "FBT001",  # boolean-typed positional argument in function definition
    "FBT002",  # boolean default positional argument in function definition
    "FBT003",  # boolean positional value in function call
    "B006",    # mutable argument as default in function
    "ANN002",  # missing type args annotations
    "SIM118",  # in dictionary keys
    "FIX002",  # todo statements
    "TRY301",  # raise not in a try block (eg., in an if/elif statement)
    "PLR2004", # magic value in comparison
    "N803", # argument values to be lowercase (camel and pascal case are common in Pyspark code)
    "N802", # function name should be lowercase (camel and pascal case are common in Pyspark code)
    "N815", # variable in class scope should not be mixedCase (camel case is common in Pyspark code)
    "PD015", # Use `.merge` method instead of `pd.merge` function. They have equivalent functionality.
]

lint.unfixable = [
    "ERA", # make eradicate not auto-fixable
]


lint.mccabe.max-complexity = 20 # maximum number of decision points (+1)
lint.pylint.max-args = 10 # maximum number of arguments in a function (imho)
lint.pylint.max-returns = 10 # maximum number of returns in a function (imho)
lint.pylint.max-branches = 30 # maximum number of branches in a function (imho)
lint.pylint.max-statements = 100 # maximum number of statements in a function (imho)

